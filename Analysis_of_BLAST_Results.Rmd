---
title: "Analysis of BLAST Results"
author: "Alfredo H. Locht halocht@gmail.com ahlocht@dons.usfca.edu"
date: "18Oct2017"
output: github_document
---

# Introduction
## Background

The purpose of the study, Fierer et al. (2010) was to investigate a bioinformatically-enriched method to forensically identify indiviuals through their unique skin-associated bacterial colonies. 
The study aimed to address the ability to identify individuals based on compendial bacterial communities derived from surfaces (computer mice and/or keyboards) touched or owned by these individuals, and assessing whether the phylogenetic similarites between an individual's property (their mouse/keyboards), and their hands was significant enough to establish a correlational identification of that individual to their property.

The criteria developed to establish such correlations included both the composition and the structure of the bacterial "fingerprint" colonies, as well as comparing an individual's bacterial fingerprint colonies to that of the general population and objects that the indiviudal had not come into contact with.

This study therefore, represents the ability to use bioinformatically-derived data to supplement or replace current forensic technqiues to not only identify individuals, but also realize that we have now entered an era where complete anonymity is no longer possible.


# Methods

## Preliminary Bacterial Stability Study

To confirm whether it was even possible to identify an individual through their own unique bacterial "fingerprint", it was necessary to first verify that the residual bacterial communities left on objects maintained their compositional and structural integrity. What is meant by this is that the researchers needed to validate that all the bacteria present at the time of sampling remained alive and present in a normal environment that consistently can vary in temperature, UV exposure, humidty, and other variables. This was accomplished by swabbing skin surfaces of individuals with dry cotton swabs and separating the samples by immediately placing one sample at -20 degrees celsius and leaving the other sample on an open benchtop at around ambient temperature. Once the results were verified to remain essentially equivalent (the bacterial composition did not change significantly), the researchers were able to proceed with their investigation.

## Sampling

### Keyboards

Keyboards of 25-30 keys per keyboard were swabbed along with the ventral surface of the distal joint of the fingertips of the keyboard owners or main users. When swabbing of the keyboards occurred, the keyboards had not been used in at least 30 min and all sampling was completed within 10 minutes of the first sample. All participants were between 20-35 years of age with no record of antibiotic use in the last six months.

Space bars from keyboards from the general populous were also swabbed for general comparison. All samples were stored at -80 degrees celsius for one week before DNA extraction.

### Computer Mice

The entire surface of the mouse as well as the entire palm of the participants was swabbed as described above taking into account that it had been less than 12 hrs between the last use of the computer mouse. The participants were in the same age range as the ones in the keyboard and the samples were handled in the exact same manner before DNA extraction.


## Computational

#### Keyboard Analysis

Pairwise unweighted and weighted distances were calculated on matches between the bacterial communities on the keyboards and the owners of the keyboards to assess the difference in using bacterial composition or colonial structure to identify an individual. The UniFrac algorithm was used to calculate the weighted distances and,"... Uses the degree of phylogenetic overlap between any pair of communities with points that are close together representing samples with similar bacterial communities."

# Results

```{r load-libraries, message = FALSE}
# Be sure to install these packages before running this script
# They can be installed either with the intall.packages() function
# or with the 'Packages' pane in RStudio

# load packages
library("dplyr")
library("tidyr")
library("knitr")
library("ggplot2")

```

```{r make-read-in-data-function}
# Output format from BLAST is as detailed on:
# https://www.ncbi.nlm.nih.gov/books/NBK279675/
# In this case, we used: '10 sscinames std'
# 10 means csv format
# sscinames means unique Subject Scientific Name(s), separated by a ';'
# std means the standard set of result columns, which are:
# 'qseqid sseqid pident length mismatch
# gapopen qstart qend sstart send evalue bitscore',


# this function takes as input a quoted path to a BLAST result file
# and produces as output a dataframe with proper column headers
# and the 'qseqid' column split into sample and seq number
read_blast_output <- function(filename) {
  data_in <- read.csv(filename,
                      header = FALSE, # files don't have column names in them
                      col.names = c("sscinames", # unique Subject Sci Name(s)
                                    "qseqid",    # Query Seq-id
                                    "sseqid",    # Subject Seq-id
                                    "pident",    # Percntge of identical matches
                                    "length",    # Alignment length
                                    "mismatch",  # Number of mismatches
                                    "gapopen",   # Number of gap openings
                                    "qstart",    # Start of alignment in query
                                    "qend",      # End of alignment in query
                                    "sstart",    # Start of alignment in subj
                                    "send",      # End of alignment in subject
                                    "evalue",    # Expect value
                                    "bitscore"))  # Bit score

  # Next we want to split the query sequence ID into
  # Sample and Number components so we can group by sample
  # They originally look like "ERR1942280.1"
  # and we want to split that into two columns: "ERR1942280" and "1"
  # we can use the separate() function from the tidyr library to do this
  # Note that we have to double escape the period for this to work
  # the syntax is
  # separate(column_to_separate,
  # c("New_column_name_1", "New_column_name_2"),
  # "seperator")
  data_in <- data_in %>%
    separate(qseqid, c("sample_name", "sample_number"), "\\.")
}
```

```{r read-in-BLAST-data}
# this makes a vector of all the BLAST output file names, including
# the name(s) of the directories they are in
files_to_read_in <- list.files(path = "output/blast",
                               full.names = TRUE)

# We need to create an empty matrix with the right number of columns
# so that we can rbind() each dataset on to it
joined_blast_data <- matrix(nrow = 0,
                           ncol = 14)
# now we loop over each of the files in the list and append them
# to the bottom of the 'joined_blast_data' object
# we do this with the rbind() function and the function we
# made earlier to read in the files, read_blast_output()
for (filename in files_to_read_in) {
  joined_blast_data <- rbind(joined_blast_data,
                             read_blast_output(filename))
}

```

```{r read-in-metadata-and-join}
# Next we want to read in the metadata file so we can add that in too
# This is not a csv file, so we have to use a slightly different syntax
# here the `sep = "\t"` tells the function that the data are tab-delimited
# and the `stringsAsFactors = FALSE` tells it not to assume that things are
# categorical variables
metadata_in <- read.table(paste0("data/metadata/",
                                 "fierer_forensic_hand_mouse_SraRunTable.txt"),
                          sep = "\t",
                          header = TRUE,
                          stringsAsFactors = FALSE)

# Finally we use the left_join() function from dplyr to merge or 'join' the
# combined data and metadata into one big table, so it's easier to work with
# in R the `by = c("Run_s" = "sample_name")` syntax tells R which columns
# to match up when joining the datasets together
joined_blast_data_metadata <- metadata_in %>%
  left_join(joined_blast_data,
            by = c("Run_s" = "sample_name"))
```


```{r histograms}
# Here we're using the dply piping syntax to select a subset of rows matching a
# criteria we specify (using the filter) function, and then pull out a column
# from the data to make a histogram. We don't need to tell the hist() function
# which data to use, because that's piped in, but we do have to give the
# hist() function the title and axis label we'd like to use for the figure
joined_blast_data_metadata %>%
  filter(env_material_s == "sebum") %>%
  pull(pident) %>%
  hist(main = "Percent Identity",
       xlab = "Percent")
```




``` {Figures Created by me}

# These are all of the figures created by me for the assignment. They focus on percent identity match across sexes (male, female and not applicable). 
joined_blast_data_metadata %>%
  filter(sex_s == "female") %>%
  pull(pident) %>%
  hist(main = "Percent Identity in Females",
       xlab = "Percent Match")
       
joined_blast_data_metadata %>%
  filter(sex_s == "male") %>%
  pull(pident) %>%
  hist(main = "Percent Identity in Males",
       xlab = "Percent Match")
       
joined_blast_data_metadata %>%
  filter(sex_s == "Not applicable") %>%
  pull(pident) %>%
  hist(main = "Percent Identity in Non-Applicable Gender",
       xlab = "Percent Match")

```


```{r summary-table}
# Finally, we'd like to be able to make a summary table of the counts of
# sequences for each taxa for each sample. To do that we can use the table()
# function. We add the kable() function as well (from the tidyr package)
# in order to format the table nicely when the document is knitted
kable(table(joined_blast_data_metadata$sscinames,
            joined_blast_data_metadata$Run_s))
```



# Discussion

Add 2-3 paragraphs here interpreting your results and considering future directions one might take in analyzing these data.

